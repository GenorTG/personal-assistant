llama-cpp-python[server]>=0.2.23
pydantic>=2.6.0
pydantic-settings>=2.1.0
openai>=1.0.0
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
httpx>=0.26.0
aiohttp>=3.9.0
huggingface_hub>=0.20.0
